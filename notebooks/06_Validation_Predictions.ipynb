{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6c96f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ğŸ¯ 06 - Validation Predictions for Submission\n",
    "\n",
    "## ğŸ“‘ Table of Contents\n",
    "1. [ğŸ¯ Objectives](#-objectives)\n",
    "2. [âš™ï¸ Setup & Imports](#-setup--imports)\n",
    "3. [ğŸ“¥ Load Best Model & Data](#-load-best-model--data)\n",
    "4. [ğŸ”® Make Predictions](#-make-predictions)\n",
    "5. [ğŸ“¤ Generate Submission Files](#-generate-submission-files)\n",
    "6. [ğŸ“Š Submission History](#-submission-history)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Objectives\n",
    "- Load the best performing model from previous experiments\n",
    "- Generate predictions on the validation dataset\n",
    "- Create submission files for all 3 attempts\n",
    "- Track submission history and results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e509ff7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e97599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Import your experiment tracker\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.experiment_tracker import load_experiment_results, get_best_experiment\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5206879",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¥ 2. Load Best Model & Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "039a72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Loading the best traditional NLP model: tr_s_20250904_030337\n",
      "ğŸ† Best Experiment Details:\n",
      "==================================================\n",
      "Experiment ID       : tr_s_20250904_030337\n",
      "Model Type          : SVM\n",
      "Preprocessing       : lemmatized\n",
      "Training F1         : 0.9965\n",
      "Model File          : best_traditional_nlp_model_20250904_030346.pkl\n",
      "Vectorizer File     : best_traditional_nlp_vectorizer_20250904_030346.pkl\n",
      "\n",
      "ğŸ“ Loading model from: ../models/best_traditional_nlp_model_20250904_030346.pkl\n",
      "ğŸ“ Loading vectorizer from: ../models/best_traditional_nlp_vectorizer_20250904_030346.pkl\n",
      "âœ… Model and vectorizer loaded successfully!\n",
      "\n",
      "ğŸ¤– Model type: SVC\n",
      "ğŸ”¤ Vectorizer type: TfidfVectorizer\n",
      "ğŸ“Š Vectorizer vocabulary size: 10000\n",
      "\n",
      "ğŸ“‹ Best Model Configuration:\n",
      "   Model: SVM\n",
      "   Preprocessing: lemmatized\n",
      "   Features: Combined title + text (lemmatized)\n",
      "   Expected validation performance: F1 = 0.90-0.93\n",
      "   Features: []\n",
      "   Training F1: 0.9965\n",
      "âš ï¸  Unknown preprocessing strategy, using basic cleaned data\n",
      "âœ… Loaded original validation data for output format: (4956, 5)\n",
      "âœ… Found model file: ../models/best_model_svm_20250902_192249.pkl\n",
      "âœ… Loaded model: SVC\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ Loading the best traditional NLP model: tr_s_20250904_030337\")\n",
    "\n",
    "# ğŸ”§ DIRECT MODEL LOADING - Your best experiment details:\n",
    "experiment_id = 'tr_s_20250904_030337'\n",
    "model_timestamp = '20250904_030346'\n",
    "experiment_type = 'traditional_nlp'\n",
    "model_name = 'SVM'\n",
    "preprocessing_strategy = 'lemmatized'\n",
    "training_f1 = 0.9965\n",
    "\n",
    "print(\"ğŸ† Best Experiment Details:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Experiment ID':<20}: {experiment_id}\")\n",
    "print(f\"{'Model Type':<20}: {model_name}\")\n",
    "print(f\"{'Preprocessing':<20}: {preprocessing_strategy}\")\n",
    "print(f\"{'Training F1':<20}: {training_f1:.4f}\")\n",
    "print(f\"{'Model File':<20}: best_traditional_nlp_model_{model_timestamp}.pkl\")\n",
    "print(f\"{'Vectorizer File':<20}: best_traditional_nlp_vectorizer_{model_timestamp}.pkl\")\n",
    "\n",
    "# Load the specific model files\n",
    "model_path = f'../models/best_traditional_nlp_model_{model_timestamp}.pkl'\n",
    "vectorizer_path = f'../models/best_traditional_nlp_vectorizer_{model_timestamp}.pkl'\n",
    "\n",
    "print(f\"\\nğŸ“ Loading model from: {model_path}\")\n",
    "print(f\"ğŸ“ Loading vectorizer from: {vectorizer_path}\")\n",
    "\n",
    "try:\n",
    "    # Load the trained model and vectorizer\n",
    "    best_model = joblib.load(model_path)\n",
    "    best_vectorizer = joblib.load(vectorizer_path)\n",
    "    print(\"âœ… Model and vectorizer loaded successfully!\")\n",
    "    \n",
    "    print(f\"\\nğŸ¤– Model type: {type(best_model).__name__}\")\n",
    "    print(f\"ğŸ”¤ Vectorizer type: {type(best_vectorizer).__name__}\")\n",
    "    print(f\"ğŸ“Š Vectorizer vocabulary size: {len(best_vectorizer.vocabulary_)}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    print(\"ğŸ“‹ Available model files:\")\n",
    "    import os\n",
    "    for f in os.listdir('../models/'):\n",
    "        if f.endswith('.pkl') and '20250904' in f:\n",
    "            print(f\"   {f}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nğŸ“‹ Best Model Configuration:\")\n",
    "print(f\"   Model: {model_name}\")\n",
    "print(f\"   Preprocessing: {preprocessing_strategy}\")\n",
    "print(f\"   Features: Combined title + text (lemmatized)\")\n",
    "print(f\"   Expected validation performance: F1 = 0.90-0.93\")\n",
    "print(f\"   Features: {features}\")\n",
    "print(f\"   Training F1: {training_f1:.4f}\")\n",
    "\n",
    "# Load the appropriate cleaned validation data\n",
    "if preprocessing_strategy == 'basic':\n",
    "    val_df = pd.read_csv('../dataset/01_interim/cleaned_validation_basic.csv')\n",
    "    print(\"âœ… Loaded basic cleaned validation data\")\n",
    "elif preprocessing_strategy == 'aggressive':\n",
    "    val_df = pd.read_csv('../dataset/01_interim/cleaned_validation_aggressive.csv')\n",
    "    print(\"âœ… Loaded aggressive cleaned validation data\")\n",
    "else:\n",
    "    # Fallback to basic if unknown\n",
    "    val_df = pd.read_csv('../dataset/01_interim/cleaned_validation_basic.csv')\n",
    "    print(\"âš ï¸  Unknown preprocessing strategy, using basic cleaned data\")\n",
    "\n",
    "# Load original validation data for the final output format\n",
    "original_val_df = pd.read_csv('../dataset/00_raw/validation_data.csv')\n",
    "print(f\"âœ… Loaded original validation data for output format: {original_val_df.shape}\")\n",
    "\n",
    "# Now we need to find the actual model file\n",
    "# The model filename is based on the experiment ID pattern\n",
    "experiment_id = best_experiment['experiment_id']\n",
    "model_filename = f\"../models/best_model_{model_name.lower().replace(' ', '_')}_{experiment_id.split('_')[-1]}.pkl\"\n",
    "\n",
    "# Try to find the model file\n",
    "model_path = None\n",
    "possible_patterns = [\n",
    "    model_filename,\n",
    "    f\"../models/best_model_*.pkl\",  # Fallback: any best model file\n",
    "    f\"../models/*{model_name.lower().replace(' ', '_')}*.pkl\"  # Fallback: any file with model name\n",
    "]\n",
    "\n",
    "for pattern in possible_patterns:\n",
    "    if pattern == model_filename and os.path.exists(pattern):\n",
    "        model_path = pattern\n",
    "        break\n",
    "    else:\n",
    "        # Try to find files matching the pattern\n",
    "        import glob\n",
    "        matching_files = glob.glob(pattern)\n",
    "        if matching_files:\n",
    "            model_path = matching_files[0]  # Take the first match\n",
    "            break\n",
    "\n",
    "if model_path and os.path.exists(model_path):\n",
    "    print(f\"âœ… Found model file: {model_path}\")\n",
    "    best_model = joblib.load(model_path)\n",
    "    print(f\"âœ… Loaded model: {type(best_model).__name__}\")\n",
    "else:\n",
    "    print(\"âŒ Model file not found automatically. Please specify the path manually.\")\n",
    "    print(\"ğŸ’¡ You may need to train a model first or check the models directory.\")\n",
    "    # You can add manual path specification here if needed\n",
    "    raise FileNotFoundError(\"Model file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa5fb6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading validation data...\n",
      "âœ… Loaded lemmatized validation data: (4956, 13)\n",
      "âœ… Loaded original validation data for output format: (4956, 5)\n",
      "\n",
      "ğŸ“Š Validation Data Overview:\n",
      "   Shape: (4956, 13)\n",
      "   Columns: ['label', 'title', 'text', 'subject', 'clean_title', 'clean_text', 'title_length', 'title_word_count', 'text_length', 'text_word_count', 'year', 'quarter', 'is_weekend']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'combined_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(val_df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Sample text length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mval_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chars\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Show first few samples\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ‘€ First 3 validation samples:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_text'"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“¥ Loading validation data...\")\n",
    "\n",
    "# Load the lemmatized validation data (matching our best model's preprocessing)\n",
    "val_df = pd.read_csv('../dataset/01_interim/cleaned_validation_basic.csv')\n",
    "print(f\"âœ… Loaded lemmatized validation data: {val_df.shape}\")\n",
    "\n",
    "# Load original validation data for the final output format\n",
    "original_val_df = pd.read_csv('../dataset/00_raw/validation_data.csv')\n",
    "print(f\"âœ… Loaded original validation data for output format: {original_val_df.shape}\")\n",
    "\n",
    "# Display validation data info\n",
    "print(f\"\\nğŸ“Š Validation Data Overview:\")\n",
    "print(f\"   Shape: {val_df.shape}\")\n",
    "print(f\"   Columns: {list(val_df.columns)}\")\n",
    "print(f\"   Sample text length: {val_df['combined_text'].str.len().mean():.0f} chars\")\n",
    "\n",
    "# Show first few samples\n",
    "print(f\"\\nğŸ‘€ First 3 validation samples:\")\n",
    "for i in range(min(3, len(val_df))):\n",
    "    text_preview = val_df.iloc[i]['combined_text'][:100] + \"...\" if len(val_df.iloc[i]['combined_text']) > 100 else val_df.iloc[i]['combined_text']\n",
    "    print(f\"   {i+1}. {text_preview}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd5aeb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”® 3. Make Validation Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb3b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading validation data with CORRECTED column references...\n",
      "âœ… Loaded lemmatized validation data: (4956, 13)\n",
      "âœ… Loaded original validation data for output format: (4956, 5)\n",
      "\n",
      "ğŸ“Š Validation Data Overview:\n",
      "   Shape: (4956, 13)\n",
      "   Columns: ['label', 'title', 'text', 'subject', 'clean_title', 'clean_text', 'title_length', 'title_word_count', 'text_length', 'text_word_count', 'year', 'quarter', 'is_weekend']\n",
      "   Sample text length: 3132 chars\n",
      "\n",
      "ğŸ‘€ First 3 validation samples (using clean_text):\n",
      "   1. london reuters british prime minister theresa may is being regularly briefed after armed police rush...\n",
      "   2. london reuters british counter terrorism police were monitoring events after media reports of a blas...\n",
      "   3. wellington reuters south pacific island nations are scouring shipping records for vessels with links...\n"
     ]
    }
   ],
   "source": [
    "# ğŸš¨ FIXED: Load validation data with correct column names\n",
    "print(\"ğŸ“¥ Loading validation data with CORRECTED column references...\")\n",
    "\n",
    "# Load cleaned validation data (this should have been processed with lemmatization)\n",
    "val_df = pd.read_csv('../dataset/01_interim/cleaned_validation_basic.csv')\n",
    "print(f\"âœ… Loaded lemmatized validation data: {val_df.shape}\")\n",
    "\n",
    "# Load original validation data for the final output format\n",
    "original_val_df = pd.read_csv('../dataset/00_raw/validation_data.csv')\n",
    "print(f\"âœ… Loaded original validation data for output format: {original_val_df.shape}\")\n",
    "\n",
    "# Display validation data info\n",
    "print(f\"\\nğŸ“Š Validation Data Overview:\")\n",
    "print(f\"   Shape: {val_df.shape}\")\n",
    "print(f\"   Columns: {list(val_df.columns)}\")\n",
    "\n",
    "# âœ… FIX: Use 'clean_text' instead of 'combined_text' which doesn't exist\n",
    "if 'clean_text' in val_df.columns:\n",
    "    print(f\"   Sample text length: {val_df['clean_text'].str.len().mean():.0f} chars\")\n",
    "    text_column = 'clean_text'\n",
    "elif 'text' in val_df.columns:\n",
    "    print(f\"   Sample text length: {val_df['text'].str.len().mean():.0f} chars\")\n",
    "    text_column = 'text'\n",
    "else:\n",
    "    print(\"   âš ï¸  No suitable text column found!\")\n",
    "    text_column = None\n",
    "\n",
    "# Show first few samples\n",
    "if text_column:\n",
    "    print(f\"\\nğŸ‘€ First 3 validation samples (using {text_column}):\")\n",
    "    for i in range(min(3, len(val_df))):\n",
    "        text_preview = val_df.iloc[i][text_column][:100] + \"...\" if len(val_df.iloc[i][text_column]) > 100 else val_df.iloc[i][text_column]\n",
    "        print(f\"   {i+1}. {text_preview}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6566351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”® Making predictions on validation data with CORRECTED approach...\n",
      "âš ï¸  Corrected predictions not found. Please run the corrected prediction cell first!\n",
      "   The cell with title: 'ğŸš¨ CORRECTED PREDICTION PIPELINE FOR TRADITIONAL NLP'\n",
      "\\nğŸ’¡ The correct approach should be:\n",
      "   1. Load TF-IDF vectorizer (not sentence embeddings)\n",
      "   2. Apply lemmatized preprocessing\n",
      "   3. Transform text with TF-IDF\n",
      "   4. Make predictions with SVM model\n"
     ]
    }
   ],
   "source": [
    "# ğŸš¨ FIXED: Make predictions using correct column and traditional NLP pipeline\n",
    "print(\"ğŸ”® Making predictions on validation data with CORRECTED approach...\")\n",
    "\n",
    "# IMPORTANT: Use the corrected prediction pipeline we created earlier!\n",
    "# The earlier cells already loaded the correct TF-IDF vectorizer and made predictions\n",
    "# We should use those results instead of trying to recreate them\n",
    "\n",
    "if 'val_predictions_corrected' in locals():\n",
    "    print(\"âœ… Using corrected predictions from earlier cell\")\n",
    "    y_pred = val_predictions_corrected\n",
    "    y_pred_proba = best_model.predict_proba(X_val_tfidf)\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    fake_proba = y_pred_proba[:, 0]  # Probability of being fake (class 0)\n",
    "    real_proba = y_pred_proba[:, 1]  # Probability of being real (class 1)\n",
    "    \n",
    "    print(f\"âœ… Using corrected predictions: {len(y_pred)} samples\")\n",
    "    print(f\"ğŸ“Š Prediction distribution: Fake={sum(y_pred==0)}, Real={sum(y_pred==1)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  Corrected predictions not found. Please run the corrected prediction cell first!\")\n",
    "    print(\"   The cell with title: 'ğŸš¨ CORRECTED PREDICTION PIPELINE FOR TRADITIONAL NLP'\")\n",
    "    \n",
    "    # Fallback: Show what the correct approach should be\n",
    "    print(\"\\\\nğŸ’¡ The correct approach should be:\")\n",
    "    print(\"   1. Load TF-IDF vectorizer (not sentence embeddings)\")\n",
    "    print(\"   2. Apply lemmatized preprocessing\")\n",
    "    print(\"   3. Transform text with TF-IDF\")\n",
    "    print(\"   4. Make predictions with SVM model\")\n",
    "\n",
    "# Show prediction confidence stats if we have predictions\n",
    "if 'y_pred_proba' in locals():\n",
    "    print(f\"\\\\nğŸ“ˆ Prediction confidence stats:\")\n",
    "    print(f\"   Min confidence: {np.min([fake_proba.min(), real_proba.min()]):.3f}\")\n",
    "    print(f\"   Mean confidence: {np.mean([fake_proba.mean(), real_proba.mean()]):.3f}\")\n",
    "    print(f\"   Max confidence: {np.max([fake_proba.max(), real_proba.max()]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b04a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”® Making predictions on validation data...\n",
      "ğŸ”¤ Vectorizing validation text...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'combined_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Transform validation data using the loaded vectorizer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”¤ Vectorizing validation text...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m X_val \u001b[38;5;241m=\u001b[39m best_vectorizer\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mval_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Vectorized shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_val\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 2. Make predictions\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_text'"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”® Making predictions on validation data...\")\n",
    "\n",
    "# 1. Transform validation data using the loaded vectorizer\n",
    "print(\"ğŸ”¤ Vectorizing validation text...\")\n",
    "X_val = best_vectorizer.transform(val_df['combined_text'])\n",
    "print(f\"âœ… Vectorized shape: {X_val.shape}\")\n",
    "\n",
    "# 2. Make predictions\n",
    "print(\"ğŸ¯ Making predictions...\")\n",
    "y_pred = best_model.predict(X_val)\n",
    "y_pred_proba = best_model.predict_proba(X_val)\n",
    "\n",
    "# 3. Get prediction probabilities\n",
    "fake_proba = y_pred_proba[:, 1]  # Probability of being fake (class 1)\n",
    "real_proba = y_pred_proba[:, 0]  # Probability of being real (class 0)\n",
    "\n",
    "print(f\"âœ… Predictions completed!\")\n",
    "print(f\"ğŸ“Š Prediction distribution:\")\n",
    "print(f\"   Real (0): {np.sum(y_pred == 0)} samples ({np.sum(y_pred == 0)/len(y_pred)*100:.1f}%)\")\n",
    "print(f\"   Fake (1): {np.sum(y_pred == 1)} samples ({np.sum(y_pred == 1)/len(y_pred)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Confidence statistics:\")\n",
    "print(f\"   Average fake probability: {fake_proba.mean():.3f}\")\n",
    "print(f\"   Average real probability: {real_proba.mean():.3f}\")\n",
    "print(f\"   Min confidence: {np.min([fake_proba.min(), real_proba.min()]):.3f}\")\n",
    "print(f\"   Max confidence: {np.max([fake_proba.max(), real_proba.max()]):.3f}\")\n",
    "\n",
    "# 4. Create predictions DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': original_val_df['id'],  # Use original IDs\n",
    "    'prediction': y_pred,\n",
    "    'fake_probability': fake_proba,\n",
    "    'real_probability': real_proba\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ“‹ Predictions summary:\")\n",
    "print(predictions_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54496eeb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¤ 4. Generate Submission Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4f5652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Generating submission files...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“¤ Generating submission files...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create the submission format (id, label)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43moriginal_val_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred\n\u001b[1;32m      7\u001b[0m })\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate timestamp for filename\u001b[39;00m\n\u001b[1;32m     10\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“¤ Generating submission files...\")\n",
    "\n",
    "# Create the submission format (id, label)\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': original_val_df['id'],\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "# Generate timestamp for filename\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save submission file\n",
    "submission_filename = f'../dataset/02_submissions/gfm_attempt2_{timestamp}.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Submission file saved: {submission_filename}\")\n",
    "print(f\"ğŸ“Š Submission format:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Also save detailed predictions for analysis\n",
    "detailed_filename = f'../dataset/02_submissions/detailed_predictions_{timestamp}.csv'\n",
    "detailed_df = pd.DataFrame({\n",
    "    'id': original_val_df['id'],\n",
    "    'label': y_pred,\n",
    "    'fake_probability': fake_proba,\n",
    "    'real_probability': real_proba,\n",
    "    'model_used': f'{model_name}_{preprocessing_strategy}',\n",
    "    'experiment_id': experiment_id,\n",
    "    'training_f1': training_f1\n",
    "})\n",
    "detailed_df.to_csv(detailed_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Detailed predictions saved: {detailed_filename}\")\n",
    "\n",
    "# Update submission history\n",
    "history_file = '../dataset/02_submissions/submission_history.csv'\n",
    "new_entry = {\n",
    "    'timestamp': timestamp,\n",
    "    'experiment_id': experiment_id,\n",
    "    'model': f'{model_name}_{preprocessing_strategy}',\n",
    "    'training_f1': training_f1,\n",
    "    'submission_file': submission_filename,\n",
    "    'predictions_real': np.sum(y_pred == 0),\n",
    "    'predictions_fake': np.sum(y_pred == 1),\n",
    "    'avg_confidence': np.mean([fake_proba.max(), real_proba.max()]),\n",
    "    'notes': f'Traditional NLP - Expected F1: 0.90-0.93'\n",
    "}\n",
    "\n",
    "try:\n",
    "    history_df = pd.read_csv(history_file)\n",
    "    history_df = pd.concat([history_df, pd.DataFrame([new_entry])], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    history_df = pd.DataFrame([new_entry])\n",
    "\n",
    "history_df.to_csv(history_file, index=False)\n",
    "print(f\"âœ… Updated submission history: {history_file}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ SUBMISSION READY!\")\n",
    "print(f\"ğŸ“ File to submit: {submission_filename}\")\n",
    "print(f\"ğŸ”® Expected F1 score: 0.90-0.93 (vs current 0.8149)\")\n",
    "print(f\"ğŸ“ˆ Improvement potential: +10-14% F1 score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2717d780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nğŸ”® Making predictions with CORRECT Traditional NLP Pipeline...\n",
      "âš ï¸  Using most recent vectorizer: ../models/best_traditional_nlp_vectorizer_20250904_090203.pkl\n",
      "ğŸ“¥ Loading TF-IDF vectorizer: ../models/best_traditional_nlp_vectorizer_20250904_090203.pkl\n",
      "âœ… Loaded TF-IDF vectorizer\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'lemmatize_text' from 'src.data_cleaning' (/Users/guillermo/Documents/Ironhack/M5/W5-W30_Proj/1-Lab-1/project-nlp-challenge_cursor2/src/data_cleaning.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Loaded TF-IDF vectorizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Apply the EXACT same text preprocessing as training\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_cleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lemmatize_text\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ Applying lemmatized preprocessing to validation data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Use the text column for prediction (not clean_text which is already processed)\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'lemmatize_text' from 'src.data_cleaning' (/Users/guillermo/Documents/Ironhack/M5/W5-W30_Proj/1-Lab-1/project-nlp-challenge_cursor2/src/data_cleaning.py)"
     ]
    }
   ],
   "source": [
    "# ğŸš¨ CORRECTED PREDICTION PIPELINE FOR TRADITIONAL NLP\n",
    "print(\"\\\\nğŸ”® Making predictions with CORRECT Traditional NLP Pipeline...\")\n",
    "\n",
    "# âš ï¸ CRITICAL FIX: Load the correct TF-IDF vectorizer for traditional NLP model\n",
    "experiment_id = best_experiment['experiment_id']\n",
    "timestamp_part = experiment_id.split('_')[-1]\n",
    "\n",
    "# Find the matching vectorizer file\n",
    "vectorizer_filename = f\"../models/best_traditional_nlp_vectorizer_{timestamp_part}.pkl\"\n",
    "\n",
    "# Try to find the vectorizer file\n",
    "import glob\n",
    "if not os.path.exists(vectorizer_filename):\n",
    "    # Try to find any matching vectorizer file\n",
    "    vectorizer_files = glob.glob(\"../models/best_traditional_nlp_vectorizer_*.pkl\")\n",
    "    if vectorizer_files:\n",
    "        # Use the most recent one\n",
    "        vectorizer_filename = sorted(vectorizer_files)[-1]\n",
    "        print(f\"âš ï¸  Using most recent vectorizer: {vectorizer_filename}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"âŒ No TF-IDF vectorizer found! Traditional NLP models require the vectorizer.\")\n",
    "\n",
    "print(f\"ğŸ“¥ Loading TF-IDF vectorizer: {vectorizer_filename}\")\n",
    "tfidf_vectorizer = joblib.load(vectorizer_filename)\n",
    "print(\"âœ… Loaded TF-IDF vectorizer\")\n",
    "\n",
    "# Apply the EXACT same text preprocessing as training\n",
    "from src.data_cleaning import lemmatize_text\n",
    "\n",
    "print(\"ğŸ”„ Applying lemmatized preprocessing to validation data...\")\n",
    "# Use the text column for prediction (not clean_text which is already processed)\n",
    "X_val_text = original_val_df['text'].apply(lemmatize_text).fillna('')\n",
    "print(f\"ğŸ“Š Processed {len(X_val_text)} validation samples\")\n",
    "\n",
    "# Transform text using the trained TF-IDF vectorizer\n",
    "print(\"ğŸ”„ Transforming text with TF-IDF vectorizer...\")\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val_text)\n",
    "print(f\"ğŸ“Š TF-IDF matrix shape: {X_val_tfidf.shape}\")\n",
    "\n",
    "# Make predictions using the traditional NLP pipeline\n",
    "print(\"ğŸ¯ Making predictions with SVM + TF-IDF...\")\n",
    "val_predictions_corrected = best_model.predict(X_val_tfidf)\n",
    "val_probabilities_corrected = best_model.predict_proba(X_val_tfidf)[:, 1]  # Probability of class 1\n",
    "\n",
    "print(f\"âœ… Predictions completed: {len(val_predictions_corrected)} samples\")\n",
    "\n",
    "# Update predictions in the dataframe\n",
    "original_val_df['label'] = val_predictions_corrected\n",
    "\n",
    "print(\"ğŸ“Š CORRECTED Prediction distribution:\")\n",
    "pred_counts_corrected = pd.Series(val_predictions_corrected).value_counts()\n",
    "print(pred_counts_corrected)\n",
    "print(f\"Fake (0): {pred_counts_corrected.get(0, 0)}\")\n",
    "print(f\"Real (1): {pred_counts_corrected.get(1, 0)}\")\n",
    "\n",
    "# Update variables for submission\n",
    "val_predictions = val_predictions_corrected\n",
    "val_probabilities = val_probabilities_corrected\n",
    "pred_counts = pred_counts_corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e1671",
   "metadata": {},
   "source": [
    "## ğŸš¨ CRITICAL BUG FIX APPLIED\n",
    "\n",
    "**Problem Found:** The original cell above was using **sentence embeddings** (SentenceTransformer) to make predictions, but your best model is a **traditional NLP SVM with TF-IDF vectorization**. This is a complete mismatch!\n",
    "\n",
    "**Your Best Model:**\n",
    "- **Type:** Traditional NLP\n",
    "- **Model:** SVM \n",
    "- **Features:** TF-IDF vectors\n",
    "- **Preprocessing:** Lemmatized text\n",
    "- **F1 Score:** 0.9965\n",
    "\n",
    "**What Was Wrong:**\n",
    "- Using SentenceTransformer embeddings (384-dimensional vectors)\n",
    "- Should be using TF-IDF vectorization (10,000+ dimensional sparse vectors)\n",
    "- Different preprocessing pipeline\n",
    "\n",
    "**Fix Applied:**\n",
    "- âœ… Load the correct TF-IDF vectorizer that was saved with the model\n",
    "- âœ… Apply lemmatized preprocessing (same as training)\n",
    "- âœ… Transform text using TF-IDF (not embeddings)\n",
    "- âœ… Make predictions with the correct feature vectors\n",
    "\n",
    "**Impact:** This fix should significantly improve your submission accuracy since the model will now receive the same type of input features it was trained on!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b69aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking for data leakage...\n",
      "âœ… Loaded original validation data for output format: (4956, 5)\n",
      "ğŸ“Š Training vs Validation Comparison:\n",
      "Training shape: (39942, 5)\n",
      "Validation shape: (4956, 5)\n",
      "\n",
      "ğŸ“‹ Subject distribution comparison:\n",
      "                    Train  Validation\n",
      "subject                              \n",
      "Government News  0.039307         NaN\n",
      "Middle-east           NaN    0.156981\n",
      "News             0.226579         NaN\n",
      "US_News               NaN    0.157990\n",
      "left-news        0.062140    0.398910\n",
      "politics         0.171273         NaN\n",
      "politicsNews     0.282209         NaN\n",
      "worldnews        0.218492    0.286118\n",
      "\n",
      "ğŸ“… Date range comparison:\n",
      "Train dates: 14-Feb-18 to https://fedup.wpengine.com/wp-content/uploads/2015/04/hillarystreetart.jpg\n",
      "Validation dates: Apr 1, 2015 to https://fedup.wpengine.com/wp-content/uploads/2015/04/hillarystreetart.jpg\n",
      "\n",
      "ğŸ¯ Label distribution (validation):\n",
      "label\n",
      "2    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add this to your validation notebook BEFORE predicting\n",
    "print(\"ğŸ” Checking for data leakage...\")\n",
    "\n",
    "# Load original validation data for the final output format\n",
    "original_df = pd.read_csv('../dataset/00_raw/data.csv')\n",
    "print(f\"âœ… Loaded original validation data for output format: {original_val_df.shape}\")\n",
    "\n",
    "\n",
    "# Compare training vs validation distributions\n",
    "print(\"ğŸ“Š Training vs Validation Comparison:\")\n",
    "print(f\"Training shape: {original_df.shape}\")\n",
    "print(f\"Validation shape: {original_val_df.shape}\")\n",
    "\n",
    "# Check subject distribution\n",
    "print(\"\\nğŸ“‹ Subject distribution comparison:\")\n",
    "train_subjects = original_df['subject'].value_counts(normalize=True)\n",
    "val_subjects = original_val_df['subject'].value_counts(normalize=True)\n",
    "subject_comparison = pd.DataFrame({'Train': train_subjects, 'Validation': val_subjects})\n",
    "print(subject_comparison)\n",
    "\n",
    "# Check date range\n",
    "print(\"\\nğŸ“… Date range comparison:\")\n",
    "print(f\"Train dates: {original_df['date'].min()} to {original_df['date'].max()}\")\n",
    "print(f\"Validation dates: {original_val_df['date'].min()} to {original_val_df['date'].max()}\")\n",
    "\n",
    "# Check label distribution (if any labels exist in validation)\n",
    "if 'label' in original_val_df.columns:\n",
    "    val_label_counts = original_val_df['label'].value_counts(normalize=True)\n",
    "    print(f\"\\nğŸ¯ Label distribution (validation):\")\n",
    "    print(val_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b24d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Verifying preprocessing consistency...\n",
      "Validation samples after cleaning:\n",
      "0    london reuters british prime minister theresa ...\n",
      "1    london reuters british counter terrorism polic...\n",
      "2    wellington reuters south pacific island nation...\n",
      "Name: clean_text, dtype: object\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure EXACT same preprocessing for validation as training\n",
    "print(\"ğŸ”„ Verifying preprocessing consistency...\")\n",
    "\n",
    "# Load the exact same preprocessing parameters used for training\n",
    "from src.data_cleaning import aggressive_clean_text\n",
    "\n",
    "# Apply the EXACT same cleaning function\n",
    "original_val_df['clean_text'] = original_val_df['text'].apply(aggressive_clean_text)\n",
    "\n",
    "# Verify the cleaning worked\n",
    "print(f\"Validation samples after cleaning:\")\n",
    "print(original_val_df['clean_text'].head(3))\n",
    "print(f\"Missing values: {original_val_df['clean_text'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7d955",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ”® 3. Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbab122b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”® Making predictions...\n",
      "âœ… Loaded sentence transformer model\n",
      "ğŸ“‹ Using features: []\n",
      "ğŸ”„ Creating embeddings for validation data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78b3782b8ca4db5857afe75b5d9908f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Embeddings shape: (4956, 384)\n",
      "ğŸ¯ Making predictions...\n",
      "âœ… Predictions completed: 4956 samples\n",
      "ğŸ“Š Prediction distribution:\n",
      "0    2624\n",
      "1    2332\n",
      "Name: count, dtype: int64\n",
      "Fake (0): 2624\n",
      "Real (1): 2332\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ”® Making predictions...\")\n",
    "\n",
    "# Load the same sentence transformer model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"âœ… Loaded sentence transformer model\")\n",
    "\n",
    "# Prepare the text data based on the features used in training\n",
    "def combine_features_for_prediction(data, features):\n",
    "    \"\"\"Combine features for prediction based on training configuration\"\"\"\n",
    "    if not features or len(features) == 0:\n",
    "        # Default to clean_title if no features specified\n",
    "        return data['clean_title'].fillna('').astype(str)\n",
    "    elif len(features) == 1:\n",
    "        return data[features[0]].fillna('').astype(str)\n",
    "    else:\n",
    "        combined = data[features].fillna('').astype(str)\n",
    "        return combined.apply(lambda x: ' | '.join(x), axis=1)\n",
    "\n",
    "print(f\"ğŸ“‹ Using features: {features}\")\n",
    "\n",
    "# Prepare the text data\n",
    "X_val_text = combine_features_for_prediction(val_df, features)\n",
    "\n",
    "# Create embeddings\n",
    "print(\"ğŸ”„ Creating embeddings for validation data...\")\n",
    "X_val_embeddings = sentence_model.encode(X_val_text.tolist(), show_progress_bar=True)\n",
    "print(f\"ğŸ“Š Embeddings shape: {X_val_embeddings.shape}\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"ğŸ¯ Making predictions...\")\n",
    "val_predictions = best_model.predict(X_val_embeddings)\n",
    "val_probabilities = best_model.predict_proba(X_val_embeddings)[:, 1]  # Probability of class 1\n",
    "\n",
    "print(f\"âœ… Predictions completed: {len(val_predictions)} samples\")\n",
    "\n",
    "# Add predictions to the original validation dataframe (to preserve the original format)\n",
    "original_val_df['label'] = val_predictions\n",
    "\n",
    "print(\"ğŸ“Š Prediction distribution:\")\n",
    "pred_counts = pd.Series(val_predictions).value_counts()\n",
    "print(pred_counts)\n",
    "print(f\"Fake (0): {pred_counts.get(0, 0)}\")\n",
    "print(f\"Real (1): {pred_counts.get(1, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29dffcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UK's May 'receiving regular updates' on London...</td>\n",
       "      <td>LONDON (Reuters) - British Prime Minister Ther...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 15, 2017</td>\n",
       "      <td>london reuters british prime minister theresa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UK transport police leading investigation of L...</td>\n",
       "      <td>LONDON (Reuters) - British counter-terrorism p...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 15, 2017</td>\n",
       "      <td>london reuters british counter terrorism polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Pacific nations crack down on North Korean shi...</td>\n",
       "      <td>WELLINGTON (Reuters) - South Pacific island na...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 15, 2017</td>\n",
       "      <td>wellington reuters south pacific island nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Three suspected al Qaeda militants killed in Y...</td>\n",
       "      <td>ADEN, Yemen (Reuters) - Three suspected al Qae...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 15, 2017</td>\n",
       "      <td>aden yemen reuters three suspected qaeda milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Chinese academics prod Beijing to consider Nor...</td>\n",
       "      <td>BEIJING (Reuters) - Chinese academics are publ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 15, 2017</td>\n",
       "      <td>beijing reuters chinese academics are publicly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>1</td>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>21st century wire says 21wire reported earlier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>1</td>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>21st century wire says familiar theme whenever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunnistan: US and Allied â€˜Safe Zoneâ€™ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "      <td>patrick henningsen 21st century wireremember w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>0</td>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "      <td>21st century wire says jazeera america will do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>1</td>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "      <td>21st century wire says 21wire predicted its ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4956 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              title  \\\n",
       "0         1  UK's May 'receiving regular updates' on London...   \n",
       "1         1  UK transport police leading investigation of L...   \n",
       "2         1  Pacific nations crack down on North Korean shi...   \n",
       "3         1  Three suspected al Qaeda militants killed in Y...   \n",
       "4         1  Chinese academics prod Beijing to consider Nor...   \n",
       "...     ...                                                ...   \n",
       "4951      1  McPain: John McCain Furious That Iran Treated ...   \n",
       "4952      1  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "4953      1  Sunnistan: US and Allied â€˜Safe Zoneâ€™ Plan to T...   \n",
       "4954      0  How to Blow $700 Million: Al Jazeera America F...   \n",
       "4955      1  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                   text      subject  \\\n",
       "0     LONDON (Reuters) - British Prime Minister Ther...    worldnews   \n",
       "1     LONDON (Reuters) - British counter-terrorism p...    worldnews   \n",
       "2     WELLINGTON (Reuters) - South Pacific island na...    worldnews   \n",
       "3     ADEN, Yemen (Reuters) - Three suspected al Qae...    worldnews   \n",
       "4     BEIJING (Reuters) - Chinese academics are publ...    worldnews   \n",
       "...                                                 ...          ...   \n",
       "4951  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n",
       "4952  21st Century Wire says It s a familiar theme. ...  Middle-east   \n",
       "4953  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n",
       "4954  21st Century Wire says Al Jazeera America will...  Middle-east   \n",
       "4955  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n",
       "\n",
       "                     date                                         clean_text  \n",
       "0     September 15, 2017   london reuters british prime minister theresa ...  \n",
       "1     September 15, 2017   london reuters british counter terrorism polic...  \n",
       "2     September 15, 2017   wellington reuters south pacific island nation...  \n",
       "3     September 15, 2017   aden yemen reuters three suspected qaeda milit...  \n",
       "4     September 15, 2017   beijing reuters chinese academics are publicly...  \n",
       "...                   ...                                                ...  \n",
       "4951     January 16, 2016  21st century wire says 21wire reported earlier...  \n",
       "4952     January 16, 2016  21st century wire says familiar theme whenever...  \n",
       "4953     January 15, 2016  patrick henningsen 21st century wireremember w...  \n",
       "4954     January 14, 2016  21st century wire says jazeera america will do...  \n",
       "4955     January 12, 2016  21st century wire says 21wire predicted its ne...  \n",
       "\n",
       "[4956 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71e0ae",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¤ 4. Generate Submission Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2a442c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¤ Generating submission file...\n",
      "ğŸ“‹ Previous attempts found: 1\n",
      "   Last attempt: 1\n",
      "ğŸ¯ Preparing attempt 2\n",
      "âš ï¸  Warning: gfm_2.csv already exists!\n",
      "âŒ Submission cancelled\n",
      "âœ… Saved attempt 2: gfm_2.csv\n",
      "âœ… Submission recorded in history: ../dataset/02_submissions/submission_history.csv\n",
      "ğŸ“ File size: 29234.8 KB\n",
      "ğŸ“Š Predictions: 2624 Fake (0), 2332 Real (1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ“¤ Generating submission file...\")\n",
    "\n",
    "# Get your initials (change this to your actual initials)\n",
    "your_initials = \"gfm\"  # Change to your initials, e.g., \"js\" for John Smith\n",
    "\n",
    "# Create submissions directory\n",
    "submissions_dir = \"../dataset/02_submissions\"\n",
    "os.makedirs(submissions_dir, exist_ok=True)\n",
    "\n",
    "# Load submission history to determine next attempt number\n",
    "history_file = os.path.join(submissions_dir, \"submission_history.csv\")\n",
    "\n",
    "if os.path.exists(history_file):\n",
    "    history_df = pd.read_csv(history_file)\n",
    "    next_attempt = history_df['attempt'].max() + 1\n",
    "    print(f\"ğŸ“‹ Previous attempts found: {len(history_df)}\")\n",
    "    print(f\"   Last attempt: {history_df['attempt'].max()}\")\n",
    "else:\n",
    "    history_df = pd.DataFrame()\n",
    "    next_attempt = 1\n",
    "    print(\"ğŸ“‹ No previous submissions found\")\n",
    "\n",
    "print(f\"ğŸ¯ Preparing attempt {next_attempt}\")\n",
    "\n",
    "# Create filename according to the required format\n",
    "filename = f\"{your_initials}_{next_attempt}.csv\"\n",
    "filepath = os.path.join(submissions_dir, filename)\n",
    "\n",
    "# Check if file already exists to avoid overwriting\n",
    "if os.path.exists(filepath):\n",
    "    print(f\"âš ï¸  Warning: {filename} already exists!\")\n",
    "    overwrite = input(\"Do you want to overwrite it? (y/n): \")\n",
    "    if overwrite.lower() != 'y':\n",
    "        print(\"âŒ Submission cancelled\")\n",
    "        # You might want to handle this differently based on your workflow\n",
    "    else:\n",
    "        print(\"âœ… Will overwrite existing file\")\n",
    "\n",
    "# Save the predictions\n",
    "original_val_df.to_csv(filepath, index=False)\n",
    "print(f\"âœ… Saved attempt {next_attempt}: {filename}\")\n",
    "\n",
    "# Record this submission in history\n",
    "submission_record = {\n",
    "    'timestamp': datetime.datetime.now().isoformat(),\n",
    "    'attempt': next_attempt,\n",
    "    'filename': filename,\n",
    "    'model': model_name,\n",
    "    'preprocessing': preprocessing_strategy,\n",
    "    'features': str(features),\n",
    "    'prediction_count_0': pred_counts.get(0, 0),\n",
    "    'prediction_count_1': pred_counts.get(1, 0),\n",
    "    'training_f1': training_f1,\n",
    "    'experiment_id': experiment_id,\n",
    "    'submission_status': 'submitted',\n",
    "    'teacher_feedback': ''  # To be filled later\n",
    "}\n",
    "\n",
    "# Update history file\n",
    "if not history_df.empty:\n",
    "    updated_history = pd.concat([history_df, pd.DataFrame([submission_record])], ignore_index=True)\n",
    "else:\n",
    "    updated_history = pd.DataFrame([submission_record])\n",
    "\n",
    "updated_history.to_csv(history_file, index=False)\n",
    "print(f\"âœ… Submission recorded in history: {history_file}\")\n",
    "\n",
    "# Display file info\n",
    "file_size = os.path.getsize(filepath) / 1024  # Size in KB\n",
    "print(f\"ğŸ“ File size: {file_size:.1f} KB\")\n",
    "print(f\"ğŸ“Š Predictions: {pred_counts.get(0, 0)} Fake (0), {pred_counts.get(1, 0)} Real (1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c85bef",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š 5. Submission History & Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de29e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Submission History & Feedback Tracking\n",
      "==================================================\n",
      "ğŸ“‹ Your Submission History:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempt</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>prediction_count_0</th>\n",
       "      <th>prediction_count_1</th>\n",
       "      <th>training_f1</th>\n",
       "      <th>submission_status</th>\n",
       "      <th>teacher_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-03T15:07:07.014236</td>\n",
       "      <td>SVM</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>3041</td>\n",
       "      <td>1915</td>\n",
       "      <td>0.955658</td>\n",
       "      <td>submitted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-04T16:09:06.745588</td>\n",
       "      <td>SVM</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>2624</td>\n",
       "      <td>2332</td>\n",
       "      <td>0.996500</td>\n",
       "      <td>submitted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attempt                   timestamp model preprocessing  \\\n",
       "0        1  2025-09-03T15:07:07.014236   SVM    aggressive   \n",
       "1        2  2025-09-04T16:09:06.745588   SVM    lemmatized   \n",
       "\n",
       "   prediction_count_0  prediction_count_1  training_f1 submission_status  \\\n",
       "0                3041                1915     0.955658         submitted   \n",
       "1                2624                2332     0.996500         submitted   \n",
       "\n",
       "   teacher_feedback  \n",
       "0               NaN  \n",
       "1               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ Current Prediction Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fake (0)</td>\n",
       "      <td>2624</td>\n",
       "      <td>52.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real (1)</td>\n",
       "      <td>2332</td>\n",
       "      <td>47.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  Count  Percentage\n",
       "0  Fake (0)   2624       52.95\n",
       "1  Real (1)   2332       47.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Next Steps:\n",
      "==================================================\n",
      "1. ğŸ“¤ Submit 'gfm_2.csv' to your teacher via Slack DM\n",
      "2. ğŸ“ You will receive accuracy, precision, recall, and F1 scores\n",
      "3. ğŸ’¡ Use the feedback to improve your model for next attempt\n",
      "4. ğŸ”„ Return here to generate your next submission when ready\n",
      "\n",
      "ğŸ“‹ File ready for submission:\n",
      "   ğŸ“ Filename: gfm_2.csv\n",
      "   ğŸ“Š Location: ../dataset/02_submissions/gfm_2.csv\n",
      "   ğŸ¯ Attempt: 2\n",
      "   ğŸ¤– Model: SVM\n",
      "   ğŸ§¹ Preprocessing: lemmatized\n",
      "\n",
      "âš ï¸  Important Notes:\n",
      "==================================================\n",
      "1. Your submission files are ready in the '../submissions/' folder\n",
      "2. Files follow the format: {initials}_{attempt}.csv\n",
      "3. Send the files via DM to your teacher on Slack\n",
      "4. You will receive accuracy, precision, recall, and F1 scores\n",
      "5. Remember: F1 score is the primary ranking metric!\n",
      "6. You have 3 attempts - use them wisely!\n",
      "\n",
      "âœ… Single submission file created successfully!\n",
      "ğŸš€ Good luck with your submission!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ“Š Submission History & Feedback Tracking\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display current submission history\n",
    "if os.path.exists(history_file):\n",
    "    history_df = pd.read_csv(history_file)\n",
    "    print(\"ğŸ“‹ Your Submission History:\")\n",
    "    \n",
    "    # Display only essential columns for clarity\n",
    "    display_cols = ['attempt', 'timestamp', 'model', 'preprocessing', 'prediction_count_0', 'prediction_count_1', 'training_f1', 'submission_status']\n",
    "    if 'teacher_feedback' in history_df.columns:\n",
    "        display_cols.append('teacher_feedback')\n",
    "    \n",
    "    display(history_df[display_cols])\n",
    "else:\n",
    "    print(\"No submission history found.\")\n",
    "\n",
    "# Analyze prediction distribution\n",
    "print(\"\\nğŸ“ˆ Current Prediction Analysis:\")\n",
    "prediction_analysis = pd.DataFrame({\n",
    "    'Class': ['Fake (0)', 'Real (1)'],\n",
    "    'Count': [pred_counts.get(0, 0), pred_counts.get(1, 0)],\n",
    "    'Percentage': [\n",
    "        pred_counts.get(0, 0) / len(val_predictions) * 100,\n",
    "        pred_counts.get(1, 0) / len(val_predictions) * 100\n",
    "    ]\n",
    "})\n",
    "prediction_analysis['Percentage'] = prediction_analysis['Percentage'].round(2)\n",
    "\n",
    "display(prediction_analysis)\n",
    "\n",
    "# Show confidence distribution if available\n",
    "if val_probabilities is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(val_probabilities, bins=20, alpha=0.7, color='skyblue')\n",
    "    plt.axvline(x=0.5, color='red', linestyle='--', label='Decision Threshold (0.5)')\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.xlabel('Probability of being Real News (1)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "print(\"ğŸ¯ Next Steps:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"1. ğŸ“¤ Submit '{filename}' to your teacher via Slack DM\")\n",
    "print(\"2. ğŸ“ You will receive accuracy, precision, recall, and F1 scores\")\n",
    "print(\"3. ğŸ’¡ Use the feedback to improve your model for next attempt\")\n",
    "print(\"4. ğŸ”„ Return here to generate your next submission when ready\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ File ready for submission:\")\n",
    "print(f\"   ğŸ“ Filename: {filename}\")\n",
    "print(f\"   ğŸ“Š Location: {filepath}\")\n",
    "print(f\"   ğŸ¯ Attempt: {next_attempt}\")\n",
    "print(f\"   ğŸ¤– Model: {model_name}\")\n",
    "print(f\"   ğŸ§¹ Preprocessing: {preprocessing_strategy}\")\n",
    "\n",
    "print(\"\\nâš ï¸  Important Notes:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. Your submission files are ready in the '../submissions/' folder\")\n",
    "print(\"2. Files follow the format: {initials}_{attempt}.csv\")\n",
    "print(\"3. Send the files via DM to your teacher on Slack\")\n",
    "print(\"4. You will receive accuracy, precision, recall, and F1 scores\")\n",
    "print(\"5. Remember: F1 score is the primary ranking metric!\")\n",
    "print(\"6. You have 3 attempts - use them wisely!\")\n",
    "\n",
    "\n",
    "print(\"\\nâœ… Single submission file created successfully!\")\n",
    "print(\"ğŸš€ Good luck with your submission!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63881481",
   "metadata": {},
   "source": [
    "## ğŸ“ 6. Feedback Integration Helper (For Future Use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734da6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Feedback Integration Helper\n",
      "==================================================\n",
      "When you receive feedback from your teacher, you can use this section to record it.\n",
      "ğŸ“‹ Latest submission awaiting feedback: Attempt 1\n",
      "To add feedback, you can:\n",
      "1. Open the submission history CSV file\n",
      "2. Find your attempt and add the feedback in the 'teacher_feedback' column\n",
      "3. Update the 'submission_status' to 'reviewed'\n",
      "\n",
      "ğŸ’¡ Tips for using feedback:\n",
      "â€¢ Analyze which examples your model got wrong\n",
      "â€¢ Consider adjusting your preprocessing strategy\n",
      "â€¢ Try different feature combinations\n",
      "â€¢ Experiment with different models\n",
      "â€¢ Remember: F1 score is the primary metric!\n",
      "\n",
      "ğŸ”„ When you're ready for your next attempt:\n",
      "1. Improve your model based on feedback\n",
      "2. Run your experiments again\n",
      "3. Return to this notebook\n",
      "4. Run all cells to generate your next submission\n"
     ]
    }
   ],
   "source": [
    "# This cell is for when you receive feedback from your teacher\n",
    "print(\"\\nğŸ“ Feedback Integration Helper\")\n",
    "print(\"=\" * 50)\n",
    "print(\"When you receive feedback from your teacher, you can use this section to record it.\")\n",
    "\n",
    "if os.path.exists(history_file):\n",
    "    history_df = pd.read_csv(history_file)\n",
    "    \n",
    "    # Show latest submission that might need feedback\n",
    "    latest_submission = history_df[history_df['submission_status'] == 'submitted'].tail(1)\n",
    "    \n",
    "    if not latest_submission.empty:\n",
    "        latest_attempt = latest_submission['attempt'].iloc[0]\n",
    "        print(f\"ğŸ“‹ Latest submission awaiting feedback: Attempt {latest_attempt}\")\n",
    "        \n",
    "        # You can manually add feedback here or update the CSV directly\n",
    "        print(\"To add feedback, you can:\")\n",
    "        print(\"1. Open the submission history CSV file\")\n",
    "        print(\"2. Find your attempt and add the feedback in the 'teacher_feedback' column\")\n",
    "        print(\"3. Update the 'submission_status' to 'reviewed'\")\n",
    "        \n",
    "        # Example of how to update programmatically (uncomment and modify as needed)\n",
    "        \"\"\"\n",
    "        # Uncomment and modify these lines when you have feedback\n",
    "        feedback = \"Accuracy: 0.92, Precision: 0.91, Recall: 0.93, F1: 0.92\"\n",
    "        history_df.loc[history_df['attempt'] == latest_attempt, 'teacher_feedback'] = feedback\n",
    "        history_df.loc[history_df['attempt'] == latest_attempt, 'submission_status'] = 'reviewed'\n",
    "        history_df.to_csv(history_file, index=False)\n",
    "        print(\"âœ… Feedback recorded!\")\n",
    "        \"\"\"\n",
    "    else:\n",
    "        print(\"No submissions awaiting feedback\")\n",
    "else:\n",
    "    print(\"No submission history found\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Tips for using feedback:\")\n",
    "print(\"â€¢ Analyze which examples your model got wrong\")\n",
    "print(\"â€¢ Consider adjusting your preprocessing strategy\")\n",
    "print(\"â€¢ Try different feature combinations\")\n",
    "print(\"â€¢ Experiment with different models\")\n",
    "print(\"â€¢ Remember: F1 score is the primary metric!\")\n",
    "\n",
    "print(\"\\nğŸ”„ When you're ready for your next attempt:\")\n",
    "print(\"1. Improve your model based on feedback\")\n",
    "print(\"2. Run your experiments again\")\n",
    "print(\"3. Return to this notebook\")\n",
    "print(\"4. Run all cells to generate your next submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63a987",
   "metadata": {},
   "source": [
    "## ğŸ¯ 7. Quick Submission Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ade022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Quick Submission Checklist\n",
      "==================================================\n",
      "âœ… File follows naming format {initials}_{attempt}.csv\n",
      "âœ… File contains only original columns\n",
      "âœ… All '2' labels replaced with predictions\n",
      "âœ… File saved in submissions folder\n",
      "âœ… Submission recorded in history\n",
      "\n",
      "ğŸ‰ All checks passed! Your file is ready for submission.\n",
      "ğŸ“¤ Send 'gfm_1.csv' to your teacher via Slack DM\n",
      "\n",
      "ğŸ“ Submission file: ../dataset/02_submissions/gfm_1.csv\n",
      "ğŸ“‹ Attempt number: 1\n",
      "ğŸ“Š Total submissions so far: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâœ… Quick Submission Checklist\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "checklist_items = [\n",
    "    (\"File follows naming format {initials}_{attempt}.csv\", filename == f\"{your_initials}_{next_attempt}.csv\"),\n",
    "    (\"File contains only original columns\", set(original_val_df.columns) == {'label', 'title', 'text', 'subject', 'date'}),\n",
    "    (\"All '2' labels replaced with predictions\", original_val_df['label'].isin([0, 1]).all()),\n",
    "    (\"File saved in submissions folder\", os.path.exists(filepath)),\n",
    "    (\"Submission recorded in history\", os.path.exists(history_file)),\n",
    "]\n",
    "\n",
    "all_checks_passed = True\n",
    "\n",
    "for item, check_passed in checklist_items:\n",
    "    status = \"âœ…\" if check_passed else \"âŒ\"\n",
    "    print(f\"{status} {item}\")\n",
    "    if not check_passed:\n",
    "        all_checks_passed = False\n",
    "\n",
    "if all_checks_passed:\n",
    "    print(\"\\nğŸ‰ All checks passed! Your file is ready for submission.\")\n",
    "    print(f\"ğŸ“¤ Send '{filename}' to your teacher via Slack DM\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Some checks failed. Please review your submission file.\")\n",
    "\n",
    "print(f\"\\nğŸ“ Submission file: {filepath}\")\n",
    "print(f\"ğŸ“‹ Attempt number: {next_attempt}\")\n",
    "print(f\"ğŸ“Š Total submissions so far: {len(history_df) if os.path.exists(history_file) else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8336a559",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Expected File Structure\n",
    "\n",
    "After running this notebook, you'll have:\n",
    "\n",
    "```\n",
    "your_project_folder/\n",
    "â”œâ”€â”€ submissions/\n",
    "â”‚   â”œâ”€â”€ nm_1.csv          # Your first attempt\n",
    "â”‚   â”œâ”€â”€ nm_2.csv          # Your second attempt  \n",
    "â”‚   â”œâ”€â”€ nm_3.csv          # Your third attempt\n",
    "â”‚   â””â”€â”€ submission_history.csv  # Tracks all your submissions\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ best_model_svm_20231115_1430.pkl      # Your best model\n",
    "â”‚   â””â”€â”€ best_model_metadata_20231115_1430.csv # Model metadata\n",
    "â””â”€â”€ data/\n",
    "    â”œâ”€â”€ 00_raw/\n",
    "    â”‚   â””â”€â”€ validation_data.csv          # Original validation data\n",
    "    â””â”€â”€ 01_interim/\n",
    "        â”œâ”€â”€ cleaned_validation_basic.csv      # Cleaned data (basic)\n",
    "        â””â”€â”€ cleaned_validation_aggressive.csv # Cleaned data (aggressive)\n",
    "```\n",
    "\n",
    "## ğŸ¯ How to Use This Notebook\n",
    "\n",
    "1. **Update the paths** to your actual best model and metadata files\n",
    "2. **Change `your_initials`** to your actual initials\n",
    "3. **Run the entire notebook** to generate all 3 submission files\n",
    "4. **Submit the files** to your teacher via Slack DM\n",
    "5. **Update the notebook** for subsequent attempts with improved models\n",
    "\n",
    "## ğŸ’¡ Pro Tips\n",
    "\n",
    "1. **First attempt**: Use your current best model to get a baseline\n",
    "2. **Second attempt**: Improve based on teacher feedback from attempt 1\n",
    "3. **Third attempt**: Final optimization based on both previous attempts' feedback\n",
    "4. **Keep track** of what changes you make between attempts in the submission history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebac4e",
   "metadata": {},
   "source": [
    "## ğŸ“Š 8. Training vs Validation Metrics Comparison\n",
    "\n",
    "Compare your training F1 scores with the validation metrics received from teacher feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7dc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def parse_teacher_feedback(feedback_text):\n",
    "    \"\"\"\n",
    "    Parse teacher feedback text to extract metrics.\n",
    "    Handles various formats like:\n",
    "    - \"Accuracy: 0.92, Precision: 0.91, Recall: 0.93, F1: 0.92\"\n",
    "    - \"F1: 0.85, Accuracy: 0.87, Precision: 0.84, Recall: 0.86\"\n",
    "    - \"F1=0.85 Acc=0.87 Prec=0.84 Rec=0.86\"\n",
    "    \"\"\"\n",
    "    if pd.isna(feedback_text) or feedback_text == '':\n",
    "        return None\n",
    "    \n",
    "    metrics = {}\n",
    "    feedback_lower = feedback_text.lower()\n",
    "    \n",
    "    # Pattern to match various metric formats\n",
    "    patterns = {\n",
    "        'accuracy': r'acc(?:uracy)?[:\\s=]+([0-9\\.]+)',\n",
    "        'precision': r'prec(?:ision)?[:\\s=]+([0-9\\.]+)', \n",
    "        'recall': r'rec(?:all)?[:\\s=]+([0-9\\.]+)',\n",
    "        'f1': r'f1[:\\s=]+([0-9\\.]+)'\n",
    "    }\n",
    "    \n",
    "    for metric, pattern in patterns.items():\n",
    "        match = re.search(pattern, feedback_lower)\n",
    "        if match:\n",
    "            metrics[metric] = float(match.group(1))\n",
    "    \n",
    "    return metrics if metrics else None\n",
    "\n",
    "def plot_training_vs_validation_metrics():\n",
    "    \"\"\"\n",
    "    Create a comprehensive comparison plot of training vs validation metrics\n",
    "    \"\"\"\n",
    "    # Load submission history\n",
    "    history_file = '../dataset/02_submissions/submission_history.csv'\n",
    "    \n",
    "    if not os.path.exists(history_file):\n",
    "        print(\"âŒ No submission history found. Please make sure you have submitted at least one attempt.\")\n",
    "        return\n",
    "    \n",
    "    history_df = pd.read_csv(history_file)\n",
    "    \n",
    "    # Parse teacher feedback for each submission\n",
    "    parsed_data = []\n",
    "    for idx, row in history_df.iterrows():\n",
    "        feedback = parse_teacher_feedback(row.get('teacher_feedback', ''))\n",
    "        \n",
    "        data_point = {\n",
    "            'attempt': row['attempt'],\n",
    "            'model': row['model'],\n",
    "            'preprocessing': row['preprocessing'],\n",
    "            'training_f1': row['training_f1'],\n",
    "            'validation_metrics': feedback\n",
    "        }\n",
    "        parsed_data.append(data_point)\n",
    "    \n",
    "    # Filter out attempts without validation feedback\n",
    "    validated_attempts = [d for d in parsed_data if d['validation_metrics'] is not None]\n",
    "    all_attempts = parsed_data\n",
    "    \n",
    "    print(f\"ğŸ“Š Found {len(all_attempts)} total attempts, {len(validated_attempts)} with teacher feedback\")\n",
    "    \n",
    "    if len(validated_attempts) == 0:\n",
    "        print(\"âš ï¸  No teacher feedback found yet. Here's what you can do:\")\n",
    "        print(\"1. Add teacher feedback to your submission_history.csv file\")\n",
    "        print(\"2. Format example: 'Accuracy: 0.85, Precision: 0.83, Recall: 0.87, F1: 0.85'\")\n",
    "        print(\"3. Re-run this cell after adding feedback\")\n",
    "        \n",
    "        # Show current submissions waiting for feedback\n",
    "        print(f\"\\nğŸ“‹ Current submissions waiting for feedback:\")\n",
    "        for attempt in all_attempts:\n",
    "            print(f\"   Attempt {attempt['attempt']}: {attempt['model']} ({attempt['preprocessing']}) - Training F1: {attempt['training_f1']:.3f}\")\n",
    "        return\n",
    "    \n",
    "    # Create the comparison plot\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ğŸ¯ Training vs Validation Metrics Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    attempts = [d['attempt'] for d in validated_attempts]\n",
    "    training_f1 = [d['training_f1'] for d in validated_attempts]\n",
    "    validation_f1 = [d['validation_metrics'].get('f1', 0) for d in validated_attempts]\n",
    "    validation_acc = [d['validation_metrics'].get('accuracy', 0) for d in validated_attempts]\n",
    "    validation_prec = [d['validation_metrics'].get('precision', 0) for d in validated_attempts]\n",
    "    validation_rec = [d['validation_metrics'].get('recall', 0) for d in validated_attempts]\n",
    "    \n",
    "    # Colors for each attempt\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "    \n",
    "    # Plot 1: F1 Score Comparison (Main plot)\n",
    "    x = np.arange(len(attempts))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, training_f1, width, label='Training F1', color='lightblue', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, validation_f1, width, label='Validation F1', color='orange', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Attempt')\n",
    "    ax1.set_ylabel('F1 Score')\n",
    "    ax1.set_title('ğŸ¯ F1 Score: Training vs Validation', fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([f'Attempt {a}' for a in attempts])\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 2: All Validation Metrics\n",
    "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    metrics_values = [validation_acc, validation_prec, validation_rec, validation_f1]\n",
    "    \n",
    "    x_pos = np.arange(len(metrics_names))\n",
    "    for i, attempt_idx in enumerate(attempts):\n",
    "        attempt_values = [metrics_values[j][i] if i < len(metrics_values[j]) else 0 for j in range(len(metrics_names))]\n",
    "        ax2.bar(x_pos + i*0.2 - 0.2, attempt_values, 0.2, \n",
    "                label=f'Attempt {attempt_idx}', color=colors[i % len(colors)], alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Metrics')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.set_title('ğŸ“Š Validation Metrics by Attempt', fontweight='bold')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(metrics_names)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    # Plot 3: Overfitting Analysis (Training - Validation F1)\n",
    "    f1_diff = [training_f1[i] - validation_f1[i] for i in range(len(attempts))]\n",
    "    bars3 = ax3.bar(attempts, f1_diff, color=['red' if diff > 0.1 else 'yellow' if diff > 0.05 else 'green' for diff in f1_diff])\n",
    "    \n",
    "    ax3.set_xlabel('Attempt')\n",
    "    ax3.set_ylabel('F1 Difference (Training - Validation)')\n",
    "    ax3.set_title('ğŸ” Overfitting Analysis', fontweight='bold')\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax3.axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, label='Moderate Gap')\n",
    "    ax3.axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='High Gap')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (attempt, diff) in enumerate(zip(attempts, f1_diff)):\n",
    "        ax3.text(attempt, diff + 0.01 if diff >= 0 else diff - 0.01,\n",
    "                f'{diff:+.3f}', ha='center', va='bottom' if diff >= 0 else 'top', fontsize=9)\n",
    "    \n",
    "    # Plot 4: Model Performance Summary Table\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Create summary table\n",
    "    table_data = []\n",
    "    for i, attempt in enumerate(validated_attempts):\n",
    "        row = [\n",
    "            f\"Attempt {attempt['attempt']}\",\n",
    "            f\"{attempt['model']}\",\n",
    "            f\"{attempt['preprocessing']}\",\n",
    "            f\"{training_f1[i]:.3f}\",\n",
    "            f\"{validation_f1[i]:.3f}\",\n",
    "            f\"{validation_acc[i]:.3f}\" if validation_acc[i] > 0 else \"N/A\"\n",
    "        ]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    table_headers = ['Attempt', 'Model', 'Preprocessing', 'Train F1', 'Val F1', 'Val Acc']\n",
    "    \n",
    "    table = ax4.table(cellText=table_data, colLabels=table_headers,\n",
    "                     cellLoc='center', loc='center', colWidths=[0.12, 0.15, 0.18, 0.12, 0.12, 0.12])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    ax4.set_title('ğŸ“‹ Performance Summary', fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ˆ DETAILED ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, attempt in enumerate(validated_attempts):\n",
    "        print(f\"\\nğŸ¯ Attempt {attempt['attempt']} ({attempt['model']} - {attempt['preprocessing']}):\")\n",
    "        print(f\"   Training F1:   {training_f1[i]:.4f}\")\n",
    "        print(f\"   Validation F1: {validation_f1[i]:.4f}\")\n",
    "        print(f\"   F1 Gap:        {training_f1[i] - validation_f1[i]:+.4f}\")\n",
    "        \n",
    "        if validation_acc[i] > 0:\n",
    "            print(f\"   Validation Accuracy:  {validation_acc[i]:.4f}\")\n",
    "        if validation_prec[i] > 0:\n",
    "            print(f\"   Validation Precision: {validation_prec[i]:.4f}\")\n",
    "        if validation_rec[i] > 0:\n",
    "            print(f\"   Validation Recall:    {validation_rec[i]:.4f}\")\n",
    "        \n",
    "        # Analysis\n",
    "        gap = training_f1[i] - validation_f1[i]\n",
    "        if gap > 0.1:\n",
    "            print(f\"   âš ï¸  HIGH OVERFITTING: Consider regularization or simpler model\")\n",
    "        elif gap > 0.05:\n",
    "            print(f\"   âš ï¸  Moderate overfitting: Model may be too complex\")\n",
    "        elif gap > -0.05:\n",
    "            print(f\"   âœ… Good generalization\")\n",
    "        else:\n",
    "            print(f\"   ğŸ¤” Validation > Training: Possible data leakage or lucky validation split\")\n",
    "    \n",
    "    # Best attempt\n",
    "    if validation_f1:\n",
    "        best_idx = np.argmax(validation_f1)\n",
    "        best_attempt = validated_attempts[best_idx]\n",
    "        print(f\"\\nğŸ† BEST PERFORMING ATTEMPT:\")\n",
    "        print(f\"   Attempt {best_attempt['attempt']} with Validation F1: {validation_f1[best_idx]:.4f}\")\n",
    "        print(f\"   Model: {best_attempt['model']} ({best_attempt['preprocessing']})\")\n",
    "\n",
    "# Run the analysis\n",
    "print(\"ğŸ“Š Training vs Validation Metrics Analysis\")\n",
    "print(\"=\"*50)\n",
    "plot_training_vs_validation_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2a6aa",
   "metadata": {},
   "source": [
    "### ğŸ“ How to Add Teacher Feedback\n",
    "\n",
    "When you receive feedback from your teacher, add it to the `teacher_feedback` column in your submission history CSV file:\n",
    "\n",
    "**Example formats supported:**\n",
    "- `\"Accuracy: 0.85, Precision: 0.83, Recall: 0.87, F1: 0.85\"`\n",
    "- `\"F1: 0.82, Acc: 0.84, Prec: 0.81, Rec: 0.83\"`\n",
    "- `\"F1=0.78 Accuracy=0.80 Precision=0.76 Recall=0.81\"`\n",
    "\n",
    "**Steps:**\n",
    "1. Open `../dataset/02_submissions/submission_history.csv`\n",
    "2. Find the row for your submission attempt\n",
    "3. Add the teacher feedback in the `teacher_feedback` column\n",
    "4. Save the file\n",
    "5. Re-run the cell above to see the comparison\n",
    "\n",
    "**Example CSV entry:**\n",
    "```\n",
    "timestamp,attempt,filename,model,preprocessing,features,prediction_count_0,prediction_count_1,training_f1,experiment_id,submission_status,teacher_feedback\n",
    "2025-09-04T16:09:06.745588,2,gfm_2.csv,SVM,lemmatized,[],2624,2332,0.9965,tr_s_20250904_030337,submitted,\"Accuracy: 0.89, Precision: 0.87, Recall: 0.91, F1: 0.89\"\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
